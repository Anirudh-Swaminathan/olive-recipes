keywords:
    aitk
arch: llama3
recipes:
    - file: "llama3_2_qnn_config.json"
      device: npu
      ep: QNNExecutionProvider
      aitk:
        oliveFile: "phi3_5/qnn_config.json"
    - file: "llama3_2_vitis_ai_config.json"
      device: npu
      ep: VitisAIExecutionProvider
      aitk:
        oliveFile: "phi3_5/qdq_config_vitis_ai.json"
        requirementsPatches:
          - AutoGptq
        runtimeOverwrite:
          executeEp: CUDAExecutionProvider
        evalRuntime: AMDNPU
    - file: "llama3_2_ov_config.json"
      devices:
        - npu
        - cpu
        - gpu
      ep: OpenVINOExecutionProvider
    - file: "llama3_2_trtrtx_config.json"
      device: gpu
      ep: NvTensorRTRTXExecutionProvider
    - file: "llama3_2_dml_config.json"
      device: gpu
      ep: DmlExecutionProvider
    - file: "llama3_2_webgpu_config.json"
      device: gpu
      ep: WebGpuExecutionProvider
aitk:
    modelInfo:
        id: "huggingface/meta-llama/Llama-3.2-1B-Instruct"
        version: 1
